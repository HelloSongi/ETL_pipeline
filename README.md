#SCENARIO

In this project, i assummed the role of data engineer working for an international financial analysis company. The company tracks stock prices, commodities, forex rates, inflation rates. My job is to extract financial data from various sources like ApI's, websites and othyer source files provided by various financial analysis companies. After i collect the data, i extract the data of interest to my company and transform it based on the requirements and metrics given to me.
Once the transformation is fully done, i load that data into my companies database (warehouse).



#PROJECT TASKS

1. Collect data using APIs

2. Collect data using webscraping.

3. Download files to process.    

4. Read csv, xml and json file types.

5. Extract data from the above file types.

6. Transform data.

7. Use the built in logging module.

8. Save the transformed data in a ready-to-load format which data engineers can use to load the data.



#API Data fetched
![APIdata](https://user-images.githubusercontent.com/69304233/178113275-a2602b06-d6d0-4d93-8d27-f7613c8f9553.PNG)

#UDATAED API DATA - REMOVED UNNECCESARY COLUMNS
![APIdataNeccesarycolumns](https://user-images.githubusercontent.com/69304233/178113294-3aade4c8-44fa-4950-a53d-310e92f1e8ea.PNG)


#WEBSCRAPPED DATA
![webscraping](https://user-images.githubusercontent.com/69304233/178113308-c2cf1a1d-1959-49bd-9785-c672536f08fe.PNG)


